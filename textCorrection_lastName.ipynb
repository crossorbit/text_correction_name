{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95bafab-5428-429b-8397-3fd7eea9add4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Correction - fastText 활용한 OCR 오인식 보안 \n",
    "  \n",
    "[목적]\n",
    "- 주민등록증, 가족관계증명서 등 행정서류에서 이름 추출하여 OCR 변환 시, 오인식으로 잘못된 정보 처리될 수 있음(e.g. 홍길동 -> 홈길동 등)\n",
    "- 대한민국 성씨 기준으로 99.7%를 차지하는 111개 성을 기준으로 fastText 통해 학습하여 **사전에 등록된 단어(성)로 변환**하여 정확도 향상  \n",
    "  &rarr; 2자리 성씨의 경우(제갈, 사공, 선우, 남궁, 서문, 황보 등) ROI Detection 된 글자에서 **2자리 성 대상을 알수 없어 첫번째 자리만 비교할 수 있는 제한적 적용**\n",
    "\n",
    "[활용 기술/라이브러리]\n",
    "- fastText : 페이스북에서 word2vec(구글)의 단점을 보완하면서 만들어낸 알고리즘\n",
    "- 문장 속 단어들의 조합으로 워드 임베딩을 하며, 이에 따라 학습에 사용된 적이 없는 단어에 대해서도 단어 벡터를 만들 수 있음\n",
    "- 형태학적 측면의 유사성 판단 가능  \n",
    "  &rarr; 우리는 **의미가 아닌 형태의 유사성으로만 판단하기 때문에 fastText 활용** \n",
    "\n",
    "[적용 결과]\n",
    "- 1글자 비교이다 보니, 정확도 낮음  \n",
    "    > 깁 -> 백, 깉 -> 탁 처럼 초성+중성 비슷한 것 보다 초성+종성 비슷한게 더 score 높음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f23cd-eeea-4b8b-b509-c11397a38852",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3e2738c5-6dd6-4be7-a59d-311bdbde2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "import gensim.models.word2vec\n",
    "import numpy as np\n",
    "from gensim import matutils\n",
    "import re\n",
    "import pandas as pd\n",
    "from soynlp.hangle import decompose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec213347-b493-4a45-9d6a-09c8a83c5471",
   "metadata": {},
   "source": [
    "## fastText 모델\n",
    "### 학습데이터  \n",
    "[sample] 150개 성씨 대상으로 학습  \n",
    "__label__1 김  \n",
    "__label__1 이  \n",
    "__label__1 박  \n",
    "\n",
    "### 모델 생성 및 학습\n",
    "- model = FastText(학습데이터셋, min_count, ....)\n",
    "> min_count : 학습 시 지정한 숫자 보다 숫자보다 적게 발생하는 단어들은 학습하지 않음(빈도가 적은 단어들은 학습하지 않기 위함이나 우리는 문장 말뭉치가 아니여서 1로 지정)  \n",
    "  word_ngrams : default word_ngrams=1 => n-gram 사용, 0 => 미사용(word2vec과 동일)  \n",
    "  vector_size : 학습할 임베딩의 크기. 즉, 임베딩된 벡터의 차원  # 300이 적절  \n",
    "  epchs : default epchs=5 &rarr; epoch 늘려도 성능 큰 차이 없음. 오히려 예상한 결과과 다른 단어가 우선수위화 됨  \n",
    "  sg : default sg=0 => CBOW, if sg=1 => skip-gram (2가지 학습 알고리즘의 성능 차이는 크지 않음)  \n",
    "  workers : 학습시 사용하는 프로세스 개수  \n",
    "  window : context window 크기 # 5~10이 적절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "683e2d0b-e7a2-4448-af96-916453290cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 소요 시간 : 0.018907219005541265\n",
      "(148, 300)\n"
     ]
    }
   ],
   "source": [
    "corpus_path = 'name_word.txt'\n",
    "model_name = 'text_correciton_name_model'\n",
    "\n",
    "corpus = gensim.models.word2vec.Text8Corpus(corpus_path) \n",
    "\n",
    "#model = FastText(corpus, window=5, min_count=1, sg=1, word_ngrams=1, vector_size=300)\n",
    "model = FastText(corpus, window=5, min_count=1, word_ngrams=1, vector_size = 300, epochs=25)\n",
    "model.save(model_name)\n",
    "\n",
    "print(f\"학습 소요 시간 : {model.total_train_time}\")\n",
    "print(model.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e03b2-fed8-4bae-9f22-b96f450acbd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 모델 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27f2aaf4-db95-431e-a42e-b12a5609627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_model = FastText.load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1966d-d313-42c7-a58b-3938ba452dd3",
   "metadata": {},
   "source": [
    "## 공통 Function\n",
    "- word_sim : 단어 유사도 측정  \n",
    "- jamo_word : 자모 단위로 단어를 분해하여 유사도 측정하여 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "286e76dd-3a2a-4956-8b06-063b51d12cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 단어 리스트 사이의 유사도 측정\n",
    "def word_sim(word_A, word_b, model=correction_model):\n",
    "    return model.wv.n_similarity(word_A, word_b)\n",
    "\n",
    "\n",
    "# 단어를 자모 단위로 분해\n",
    "def jamo_word(sent):\n",
    "    doublespace_pattern = re.compile('\\s+')\n",
    "\n",
    "    def transform(char):\n",
    "        try:\n",
    "            if char == ' ':\n",
    "                return char\n",
    "            jamo = decompose(char)\n",
    "            \n",
    "            if len(jamo) == 1:\n",
    "                return jamo, jamo_len\n",
    "            jamo_ = ''.join(c if c != ' ' else '&' for c in jamo)\n",
    "            return jamo_\n",
    "        \n",
    "        except Exception as e: # 마침표, 물음표 반환\n",
    "            return char\n",
    "\n",
    "    sent_ = ''.join(transform(char) for char in sent)\n",
    "    sent_ = doublespace_pattern.sub(' ', sent_)\n",
    "    return sent_\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae75a6-90cb-452f-ba45-982b3bafce6e",
   "metadata": {},
   "source": [
    "## 단어 사전과 비교하여 유사성 검사\n",
    "- **jamo 분리해서 유사성 검증하면 정확도 향상**  \n",
    "- 글자수 같은 것끼리만 판단하도록 적용  \n",
    "    &rarr; 실제 오류 케이스 확인하여 1~2글자는 글자수 같을 때만 체크하고 나머지는 전체 비교할지 등 보완"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76704e1b-ff6c-429b-9f81-f0892a8fd158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 단어: 깃\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김</td>\n",
       "      <td>0.997847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>심</td>\n",
       "      <td>0.997590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>길</td>\n",
       "      <td>0.997568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relation     score\n",
       "0        김  0.997847\n",
       "1        심  0.997590\n",
       "2        길  0.997568"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = '깃'\n",
    "dictionary = ['김','이','박','최','정','강','조','윤','장','임','한','오','서','신','권','황','안','송','전','홍','유','고','문','양','손','배','백','허','남','심','노','하','곽','성','차','주','우','구','민','류','나','진','지','엄','채','원','천','방','공','현','함','변','염','여','추','도','소','석','선','설','마','길','연','위','표','명','기','반','라','왕','금','옥','육','인','맹','제','모','탁','국','어','은','편','용','예','경','봉','사','부','가','복','태','목','형','계','피','두','감','음','빈','동','온','호','범','좌','팽','승','간','상','시','갈','단','소']\n",
    "results = []\n",
    "\n",
    "for i in range(len(dictionary)):\n",
    "    \n",
    "    #1자리 비교로 해당 조건 삭제\n",
    "    #if len(word) == len(dictionary[i]):\n",
    "    result_info = {}\n",
    "    result_info['relation'] = dictionary[i]\n",
    "    result_info['score'] = word_sim( jamo_word(dictionary[i]), jamo_word(word), correction_model) \n",
    "    #result_info['score'] = word_sim(dictionary[i], word, correction_model) \n",
    "    results.append(result_info)\n",
    "        \n",
    "results = sorted(results, key=lambda d:d['score'], reverse=True)\n",
    "df = pd.DataFrame(results)\n",
    "print('입력 단어:', word)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a44ed9-afcb-4999-91aa-84fc54ff5815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
